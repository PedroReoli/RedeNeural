# Por trÃ¡s do cÃ³digo: ClassificaÃ§Ã£o de Pontos com Rede Neural

Este documento explica detalhadamente o funcionamento do cÃ³digo que implementa uma rede neural simples para classificar pontos como estando dentro ou fora de um cÃ­rculo.

## ğŸ“š SumÃ¡rio

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [FunÃ§Ãµes de AtivaÃ§Ã£o](#funÃ§Ãµes-de-ativaÃ§Ã£o)
3. [GeraÃ§Ã£o do Dataset](#geraÃ§Ã£o-do-dataset)
4. [Treinamento da Rede Neural](#treinamento-da-rede-neural)
5. [Backpropagation](#backpropagation)
6. [ComparaÃ§Ã£o: Sigmoid vs ReLU](#comparaÃ§Ã£o-sigmoid-vs-relu)
7. [Teste do Modelo](#teste-do-modelo)

## ğŸ” VisÃ£o Geral

O cÃ³digo implementa uma rede neural de camada Ãºnica (perceptron) para resolver um problema de classificaÃ§Ã£o binÃ¡ria: determinar se um ponto em um espaÃ§o bidimensional estÃ¡ dentro ou fora de um cÃ­rculo com raio 0.5 centrado na origem.

A implementaÃ§Ã£o compara duas funÃ§Ãµes de ativaÃ§Ã£o populares:
- **Sigmoid**: Uma funÃ§Ã£o suave que mapeia valores para o intervalo (0,1)
- **ReLU (Rectified Linear Unit)**: Uma funÃ§Ã£o que retorna 0 para entradas negativas e a prÃ³pria entrada para valores positivos

## âš™ï¸ FunÃ§Ãµes de AtivaÃ§Ã£o

### Sigmoid e sua Derivada

```python
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return sigmoid(x) * (1 - sigmoid(x))
```

A funÃ§Ã£o sigmoid transforma qualquer valor de entrada em um nÃºmero entre 0 e 1. Ela Ã© definida matematicamente como Ïƒ(x) = 1/(1+e^(-x)).

**CaracterÃ­sticas da Sigmoid:**
- Suave e diferenciÃ¡vel em todos os pontos
- SaÃ­da limitada entre 0 e 1 (Ãºtil para probabilidades)
- SaturaÃ§Ã£o: para valores muito grandes (positivos ou negativos), a derivada se aproxima de zero
- Sua derivada Ã© calculada como Ïƒ(x) * (1 - Ïƒ(x))

### ReLU e sua Derivada

```python
def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    return np.where(x > 0, 1, 0)
```

A funÃ§Ã£o ReLU (Rectified Linear Unit) Ã© definida como f(x) = max(0, x).

**CaracterÃ­sticas da ReLU:**
- Computacionalmente eficiente
- NÃ£o satura para valores positivos (evita o problema do desaparecimento do gradiente)
- Derivada simples: 1 para x > 0 e 0 para x â‰¤ 0
- Problema de "neurÃ´nios mortos": neurÃ´nios podem parar de aprender se sempre receberem entradas negativas

## ğŸ“Š GeraÃ§Ã£o do Dataset

```python
np.random.seed(0)  # Garante reprodutibilidade
X = np.random.uniform(-1, 1, (500, 2))  # 500 pontos aleatÃ³rios entre -1 e 1
y = (np.sqrt(X[:, 0]**2 + X[:, 1]**2) < 0.5).astype(int).reshape(-1, 1)
```

O cÃ³digo gera 500 pontos aleatÃ³rios em um quadrado de -1 a 1 em ambas as dimensÃµes. Cada ponto Ã© classificado como:
- **Classe 1 (verdadeiro)**: se estiver dentro do cÃ­rculo de raio 0.5 centrado na origem
- **Classe 0 (falso)**: se estiver fora do cÃ­rculo

A fÃ³rmula `np.sqrt(X[:, 0]**2 + X[:, 1]**2) < 0.5` calcula a distÃ¢ncia euclidiana de cada ponto atÃ© a origem (0,0) e verifica se Ã© menor que 0.5 (o raio do cÃ­rculo).

A visualizaÃ§Ã£o do dataset Ã© feita com matplotlib:

```python
plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), cmap=plt.cm.Spectral)
plt.title("Dataset: Pontos Dentro e Fora de um CÃ­rculo")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.colorbar(label="Classe")
plt.show()
```

## ğŸ§  Treinamento da Rede Neural

O treinamento Ã© implementado na funÃ§Ã£o `train_neural_network`:

```python
def train_neural_network(activation_function, activation_derivative):
    weights = np.random.randn(2, 1)  # Inicializa pesos aleatÃ³rios
    bias = np.random.randn()  # Inicializa o viÃ©s aleatoriamente
    errors = []

    for epoch in range(epochs):
        # Forward pass
        weighted_sum = np.dot(X, weights) + bias
        output = activation_function(weighted_sum)

        # CÃ¡lculo do erro
        error = y - output
        errors.append(np.mean(np.square(error)))

        # Backpropagation
        d_error = -2 * error / len(X)
        d_output = activation_derivative(weighted_sum)
        gradient = d_error * d_output

        # AtualizaÃ§Ã£o dos pesos e viÃ©s
        weights -= learning_rate * np.dot(X.T, gradient)
        bias -= learning_rate * np.sum(gradient)

        if epoch % 5000 == 0:
            print(f"Ã‰poca {epoch}, Erro: {errors[-1]}")

    return weights, bias, errors
```

### InicializaÃ§Ã£o
- Os pesos (`weights`) sÃ£o inicializados aleatoriamente com uma distribuiÃ§Ã£o normal
- O viÃ©s (`bias`) tambÃ©m Ã© inicializado aleatoriamente
- A lista `errors` armazenarÃ¡ o erro em cada Ã©poca para anÃ¡lise posterior

### Forward Pass
1. **Soma Ponderada**: `weighted_sum = np.dot(X, weights) + bias`
   - Multiplica cada entrada pelos pesos correspondentes e soma o resultado com o viÃ©s
   - Matematicamente: z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + b

2. **AtivaÃ§Ã£o**: `output = activation_function(weighted_sum)`
   - Aplica a funÃ§Ã£o de ativaÃ§Ã£o (sigmoid ou ReLU) Ã  soma ponderada
   - Transforma o valor linear em uma previsÃ£o nÃ£o-linear

## ğŸ”„ Backpropagation

O backpropagation Ã© o processo de ajustar os pesos da rede com base no erro:

1. **CÃ¡lculo do Erro**: `error = y - output`
   - DiferenÃ§a entre o valor esperado (y) e a saÃ­da prevista (output)

2. **Erro QuadrÃ¡tico MÃ©dio**: `np.mean(np.square(error))`
   - Mede a performance do modelo (menor Ã© melhor)
   - Elevamos ao quadrado para penalizar erros maiores e evitar que erros positivos e negativos se cancelem

3. **Derivada do Erro**: `d_error = -2 * error / len(X)`
   - Derivada do erro quadrÃ¡tico mÃ©dio em relaÃ§Ã£o Ã  saÃ­da
   - O fator -2 vem da derivada da funÃ§Ã£o de erro quadrÃ¡tico

4. **Derivada da AtivaÃ§Ã£o**: `d_output = activation_derivative(weighted_sum)`
   - Calcula a derivada da funÃ§Ã£o de ativaÃ§Ã£o no ponto da soma ponderada
   - Indica a taxa de mudanÃ§a da saÃ­da em relaÃ§Ã£o Ã  entrada

5. **Gradiente**: `gradient = d_error * d_output`
   - Combina as derivadas pela regra da cadeia
   - Indica a direÃ§Ã£o e magnitude para ajustar os pesos

6. **AtualizaÃ§Ã£o dos Pesos**: 
   - `weights -= learning_rate * np.dot(X.T, gradient)`
   - `bias -= learning_rate * np.sum(gradient)`
   - Ajusta os pesos e o viÃ©s na direÃ§Ã£o oposta ao gradiente
   - O learning_rate controla o tamanho do passo de atualizaÃ§Ã£o

## ğŸ“ˆ ComparaÃ§Ã£o: Sigmoid vs ReLU

O cÃ³digo treina dois modelos idÃªnticos, exceto pela funÃ§Ã£o de ativaÃ§Ã£o:

```python
weights_sigmoid, bias_sigmoid, erros_sigmoid = train_neural_network(sigmoid, sigmoid_derivative)
weights_relu, bias_relu, erros_relu = train_neural_network(relu, relu_derivative)
```

A comparaÃ§Ã£o visual Ã© feita plotando o erro ao longo das Ã©pocas:

```python
plt.plot(range(epochs), erros_sigmoid, label="Sigmoid", color='blue')
plt.plot(range(epochs), erros_relu, label="ReLU", linestyle='dashed', color='red')
plt.title("Erro ao longo do treinamento")
plt.xlabel("Ã‰poca")
plt.ylabel("Erro")
plt.legend()
plt.show()
```

**AnÃ¡lise da ComparaÃ§Ã£o:**
- A ReLU geralmente converge mais rapidamente devido Ã  sua derivada constante (1) para entradas positivas
- A Sigmoid pode ser mais estÃ¡vel para certos problemas devido Ã  sua natureza limitada
- A escolha entre elas depende do problema especÃ­fico e da arquitetura da rede

## ğŸ§ª Teste do Modelo

ApÃ³s o treinamento, o cÃ³digo testa os modelos com os primeiros 10 pontos do dataset:

```python
print("\nTeste do modelo com Sigmoid:")
for i in range(10):
    weighted_sum = np.dot(X[i], weights_sigmoid) + bias_sigmoid
    output = sigmoid(weighted_sum)
    print(f"Entrada: {X[i]}, SaÃ­da esperada: {y[i]}, SaÃ­da obtida: {output}")

print("\nTeste do modelo com ReLU:")
for i in range(10):
    weighted_sum = np.dot(X[i], weights_relu) + bias_relu
    output = relu(weighted_sum)
    print(f"Entrada: {X[i]}, SaÃ­da esperada: {y[i]}, SaÃ­da obtida: {output}")
```

Para cada ponto de teste:
1. Calcula a soma ponderada usando os pesos e viÃ©s treinados
2. Aplica a funÃ§Ã£o de ativaÃ§Ã£o correspondente
3. Compara a saÃ­da obtida com o valor esperado

**InterpretaÃ§Ã£o dos Resultados:**
- Para a Sigmoid, valores prÃ³ximos de 1 indicam pontos dentro do cÃ­rculo, e valores prÃ³ximos de 0 indicam pontos fora
- Para a ReLU, valores positivos geralmente indicam pontos dentro do cÃ­rculo, e valores prÃ³ximos de 0 indicam pontos fora
- A precisÃ£o do modelo pode ser avaliada pela proximidade entre a saÃ­da obtida e o valor esperado

## ğŸ”‘ Conceitos-Chave

1. **Perceptron**: A rede implementada Ã© um perceptron simples (rede neural de camada Ãºnica)
2. **Gradiente Descendente**: O algoritmo de otimizaÃ§Ã£o usado para minimizar o erro
3. **FunÃ§Ãµes de AtivaÃ§Ã£o**: Introduzem nÃ£o-linearidade, permitindo que a rede aprenda padrÃµes complexos
4. **Backpropagation**: O processo de propagar o erro de volta pela rede para ajustar os pesos
5. **Erro QuadrÃ¡tico MÃ©dio**: A funÃ§Ã£o de custo que mede a performance do modelo

Este cÃ³digo demonstra os fundamentos do aprendizado de mÃ¡quina e redes neurais em um problema de classificaÃ§Ã£o simples mas visualmente intuitivo.
